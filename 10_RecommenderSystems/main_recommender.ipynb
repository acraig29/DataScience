{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#from sklearn.cross_validation import KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, train_test_split, KFold, ShuffleSplit\n",
    "#from sklearn.grid_search import GridSearchCV\n",
    "import time, math\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "from datetime import date, datetime\n",
    "import os\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.impute import SimpleImputer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv(\"exports/ratings.csv\",parse_dates = True,sep=\",\")\n",
    "movies = pd.read_csv(\"exports/movies.csv\",parse_dates = True,sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6608, 4)"
      ]
     },
     "execution_count": 545,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['userId', 'movieId', 'rating', 'timestamp'], dtype='object')"
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "###join both datasets\n",
    "\n",
    "all_ratings =  pd.merge(ratings, movies, on='movieId', how='inner')\n",
    "#all_ratings.reset_index(drop=True)\n",
    "\n",
    "all_ratings.set_index('movieId', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ratings['movieId2'] = all_ratings.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>movie_year</th>\n",
       "      <th>movieId2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movieId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>964983815</td>\n",
       "      <td>Seven (a.k.a. Se7en) (1995)</td>\n",
       "      <td>Mystery|Thriller</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>945173425</td>\n",
       "      <td>Seven (a.k.a. Se7en) (1995)</td>\n",
       "      <td>Mystery|Thriller</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>845553317</td>\n",
       "      <td>Seven (a.k.a. Se7en) (1995)</td>\n",
       "      <td>Mystery|Thriller</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>839463546</td>\n",
       "      <td>Seven (a.k.a. Se7en) (1995)</td>\n",
       "      <td>Mystery|Thriller</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>987895819</td>\n",
       "      <td>Seven (a.k.a. Se7en) (1995)</td>\n",
       "      <td>Mystery|Thriller</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         userId  rating  timestamp                        title  \\\n",
       "movieId                                                           \n",
       "47            1       5  964983815  Seven (a.k.a. Se7en) (1995)   \n",
       "47            4       2  945173425  Seven (a.k.a. Se7en) (1995)   \n",
       "47            6       4  845553317  Seven (a.k.a. Se7en) (1995)   \n",
       "47            8       4  839463546  Seven (a.k.a. Se7en) (1995)   \n",
       "47           13       5  987895819  Seven (a.k.a. Se7en) (1995)   \n",
       "\n",
       "                   genres  movie_year  movieId2  \n",
       "movieId                                          \n",
       "47       Mystery|Thriller      1995.0        47  \n",
       "47       Mystery|Thriller      1995.0        47  \n",
       "47       Mystery|Thriller      1995.0        47  \n",
       "47       Mystery|Thriller      1995.0        47  \n",
       "47       Mystery|Thriller      1995.0        47  "
      ]
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>userId</th>\n",
       "      <th>1</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>...</th>\n",
       "      <th>601</th>\n",
       "      <th>602</th>\n",
       "      <th>603</th>\n",
       "      <th>604</th>\n",
       "      <th>605</th>\n",
       "      <th>606</th>\n",
       "      <th>607</th>\n",
       "      <th>608</th>\n",
       "      <th>609</th>\n",
       "      <th>610</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movieId2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1302</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1346</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2108</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2478</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2698</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>216 rows × 560 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "userId    1    3    4    5    6    7    8    9    11   12   ...  601  602  \\\n",
       "movieId2                                                    ...             \n",
       "20        NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN   \n",
       "21        NaN  NaN  1.0  1.0  1.0  NaN  1.0  NaN  NaN  NaN  ...  NaN  1.0   \n",
       "22        NaN  NaN  NaN  NaN  1.0  NaN  NaN  NaN  NaN  NaN  ...  NaN  1.0   \n",
       "23        NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN   \n",
       "24        NaN  NaN  NaN  NaN  1.0  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN   \n",
       "...       ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "1302      NaN  1.0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN   \n",
       "1346      NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN   \n",
       "2108      NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN   \n",
       "2478      1.0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN   \n",
       "2698      NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN   \n",
       "\n",
       "userId    603  604  605  606  607  608  609  610  \n",
       "movieId2                                          \n",
       "20        NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "21        1.0  NaN  NaN  NaN  NaN  1.0  NaN  NaN  \n",
       "22        NaN  1.0  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "23        NaN  1.0  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "24        NaN  NaN  NaN  NaN  NaN  1.0  NaN  NaN  \n",
       "...       ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "1302      NaN  NaN  NaN  NaN  NaN  1.0  NaN  NaN  \n",
       "1346      1.0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "2108      NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "2478      NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "2698      NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "\n",
       "[216 rows x 560 columns]"
      ]
     },
     "execution_count": 552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctab = pd.crosstab(index = all_ratings.movieId2, columns = all_ratings.userId, values = all_ratings.userId, aggfunc = 'count')\n",
    "ctab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_names =  pd.merge(ctab, all_ratings, left_on=['movieId2'], right_on=['movieId2'], how='inner')\n",
    "#movie_names =  pd.merge(ctab, all_ratings, on='movieId', how='inner')\n",
    "\n",
    "#Both_DFs = pd.merge(df1,df2, how='left',left_on=['A','B'],right_on=['A','CC']).dropna()\n",
    "movie_names = movie_names[['movieId2','title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId2</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>Money Train (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>Money Train (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>Money Train (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>Money Train (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>Money Train (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6603</th>\n",
       "      <td>2478</td>\n",
       "      <td>¡Three Amigos! (1986)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6604</th>\n",
       "      <td>2478</td>\n",
       "      <td>¡Three Amigos! (1986)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6605</th>\n",
       "      <td>2478</td>\n",
       "      <td>¡Three Amigos! (1986)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6606</th>\n",
       "      <td>2478</td>\n",
       "      <td>¡Three Amigos! (1986)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6607</th>\n",
       "      <td>2698</td>\n",
       "      <td>Zone 39 (1997)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6608 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      movieId2                  title\n",
       "0           20     Money Train (1995)\n",
       "1           20     Money Train (1995)\n",
       "2           20     Money Train (1995)\n",
       "3           20     Money Train (1995)\n",
       "4           20     Money Train (1995)\n",
       "...        ...                    ...\n",
       "6603      2478  ¡Three Amigos! (1986)\n",
       "6604      2478  ¡Three Amigos! (1986)\n",
       "6605      2478  ¡Three Amigos! (1986)\n",
       "6606      2478  ¡Three Amigos! (1986)\n",
       "6607      2698         Zone 39 (1997)\n",
       "\n",
       "[6608 rows x 2 columns]"
      ]
     },
     "execution_count": 558,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_names = movie_names.drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [],
   "source": [
    "#manual creation if the R matrix\n",
    "R = csr_matrix((all_ratings['rating'], (all_ratings['userId'], all_ratings['movieId2'])))\n",
    "\n",
    "R = R.todense()   # convert sparse matrix to dense matrix, same as: matrix_sparse.A\n",
    "R = R[1:,1:]                  # removing the \"Python starts at 0\" offset\n",
    "R = np.asarray(R) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create sparse matic and convert to dense matrix\n",
    "def ConvertToDense_new(vals, y, x):\n",
    "    R = csr_matrix((vals, (y, x)))\n",
    "\n",
    "    R = R.todense()   # convert sparse matrix to dense matrix, same as: matrix_sparse.A\n",
    "    R = R[1:,1:]                  # removing the \"Python starts at 0\" offset\n",
    "    R = np.asarray(R)\n",
    "    return R \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 561,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test code to check function X1= ratings[['userId']].values\n",
    "ConvertToDense_new(all_ratings['rating'], all_ratings['userId'], all_ratings['movieId2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert R matrix to dataframe for inspection purposes only\n",
    "Rdf = pd.DataFrame(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.003985344335208837\n"
     ]
    }
   ],
   "source": [
    "#caluclate the sparsity of the R matrix\n",
    "print(len(R.nonzero()[0]) / float(R.shape[0] * R.shape[1]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###run the nmf model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item features - M: (2698, 20)\n",
      "User features - Theta: (610, 20)\n",
      "R ~ M * Theta.T:\n",
      "[[0.   0.   0.   ... 0.   0.   0.02]\n",
      " [0.   0.   0.   ... 0.   0.   0.  ]\n",
      " [0.   0.   0.   ... 0.   0.   0.  ]\n",
      " ...\n",
      " [0.   0.   0.   ... 0.   0.   0.04]\n",
      " [0.   0.   0.   ... 0.   0.   0.  ]\n",
      " [0.   0.   0.   ... 0.   0.   0.03]]\n",
      "(610, 2698)\n"
     ]
    }
   ],
   "source": [
    "##run the nmf model\n",
    "\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "nmf_model = NMF(n_components=20)     # starts with 20 latents factors\n",
    "\n",
    "# Matrix factorization               # V ~ W.H  (Find two non-negative matrices (W, H) whose product approximates the non- negative matrix X. )\n",
    "nmf_model.fit(R)                     # R can be array-like or sparse, here it is array-like (dense)\n",
    "Theta = nmf_model.transform(R)       # user latent factors (= W, called the features matrix)\n",
    "M = nmf_model.components_.T          # item latent factors (= H.T) (H is called the coefficient matrix)\n",
    "\n",
    "# Making the predictions\n",
    "R_pred = M.dot(Theta.T)              # See http://stackoverflow.com/questions/24739121/nonnegative-matrix-factorization-in-sklearn\n",
    "R_pred = R_pred.T                    # same dimensions as R\n",
    "\n",
    "print('Item features - M:', M.shape)\n",
    "print('User features - Theta:', Theta.shape)\n",
    "\n",
    "print('R ~ M * Theta.T:')\n",
    "print(R_pred.round(2) )\n",
    "print(R_pred.shape )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [],
   "source": [
    "#userId'], ratings['movieId']\n",
    "\n",
    "def GetShape(filename):\n",
    "    names = ['userId', 'movieId2', 'rating', 'timestamp']\n",
    "    df = pd.read_csv(filename, sep=',',  names=names, header=0) \n",
    "    n_users = len(df['userId'].unique())\n",
    "    n_items = len(df['movieId2'].unique())\n",
    "    return (n_users, n_items)\n",
    "\n",
    "def LoadData(filename):\n",
    "    names = ['userId', 'movieId2', 'rating', 'timestamp']\n",
    "    #df = pd.read_csv(filename, sep='\\t', names=names)  \n",
    "    df = pd.read_csv(filename, sep=',',  names=names, header=0) \n",
    "    X = df[['userId', 'movieId2']].values\n",
    "\n",
    "    X1= df['userId'].values\n",
    "    X2= df['movieId2'].values\n",
    "    y = df['rating'].values \n",
    "\n",
    "    return X, y, ConvertToDense_new(y, X1, X2)\n",
    "\n",
    "R_shape = GetShape('exports/ratings.csv') \n",
    "R_shape\n",
    "X, y, R = LoadData('exports/ratings.csv') \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 628,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert R matrix to dataframe for inspection purposes only\n",
    "Rdf = pd.DataFrame(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[   1,   47],\n",
       "        [   1,   50],\n",
       "        [   1,   70],\n",
       "        ...,\n",
       "        [ 610,  608],\n",
       "        [ 610,  904],\n",
       "        [ 610, 1218]], dtype=int64),\n",
       " array([5, 5, 3, ..., 4, 5, 5], dtype=int64),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=int64))"
      ]
     },
     "execution_count": 564,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y, R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"X1= df['userId'].values\\n    X2= df['movieId'].values\\n    y = df['rating'].values \\n\\n    return X, y, ConvertToDense_new(y, X1, X2)\""
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''X1= df['userId'].values\n",
    "    X2= df['movieId'].values\n",
    "    y = df['rating'].values \n",
    "\n",
    "    return X, y, ConvertToDense_new(y, X1, X2)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   1,   47],\n",
       "       [   1,   50],\n",
       "       [   1,   70],\n",
       "       ...,\n",
       "       [ 610,  608],\n",
       "       [ 610,  904],\n",
       "       [ 610, 1218]], dtype=int64)"
      ]
     },
     "execution_count": 565,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X[:, 0].shape\n",
    "#X[:, 1].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(610, 2698)\n",
      "\n",
      "[[0 0 0 ... 0 0 4]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 0 4]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(610, 2478)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "\n",
    "#R_train = ConvertToDense_new(X_train, y_train, R_shape)\n",
    "#R_test = ConvertToDense_new(X_test, y_test, R_shape)\n",
    "\n",
    "#print(X_train[:,0])\n",
    "R_train = ConvertToDense_new(y_train, X_train[:,0], X_train[:,1])\n",
    "R_test = ConvertToDense_new(y_test, X_test[:,0], X_test[:,1])\n",
    "\n",
    "print(R_train)\n",
    "print(R_train)\n",
    "print(R_train.shape)\n",
    "print()\n",
    "print(R_test)\n",
    "print(R_test)\n",
    "print(R_test.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###2.3 Choose a model: and NMF paramaters to test find the best NMF model with best paramaters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "parametersNMF = {\n",
    "                    'n_components' : 20,     # number of latent factors\n",
    "                    'init' : 'random', \n",
    "                    'random_state' : 0, \n",
    "                    'alpha' : 0.01,          # regularization term\n",
    "                    'l1_ratio' : 0,          # set regularization = L2 \n",
    "                    'max_iter' : 10\n",
    "                }\n",
    "\n",
    "estimator = NMF(**parametersNMF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Estimating the error (RMSE) before tuning the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def get_rmse(pred, actual):\n",
    "    pred = pred[actual.nonzero()].flatten()     # Ignore nonzero terms\n",
    "    actual = actual[actual.nonzero()].flatten() # Ignore nonzero terms\n",
    "    return np.sqrt(mean_squared_error(pred, actual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6608,)"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:, 0][].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2382566928863525\n",
      "0.21983531594456193\n",
      "0.26427769660949707\n",
      "0.21940861033366837\n",
      "0.43485403060913086\n",
      "0.2216021525684641\n",
      "0.14461374282836914\n",
      "0.22099459180608405\n",
      "0.2892475128173828\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [111, 110]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [284], line 41\u001b[0m\n\u001b[0;32m     33\u001b[0m     R_pred \u001b[39m=\u001b[39m R_pred\u001b[39m.\u001b[39mT      \n\u001b[0;32m     35\u001b[0m     \u001b[39m# Clipping values                                                    \u001b[39;00m\n\u001b[0;32m     36\u001b[0m     \u001b[39m#R_pred[R_pred > 5] = 5.           # clips ratings above 5             \u001b[39;00m\n\u001b[0;32m     37\u001b[0m     \u001b[39m#R_pred[R_pred < 1] = 1.           # clips ratings below 1\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \n\u001b[0;32m     39\u001b[0m     \u001b[39m# Computing the error on the validation set \u001b[39;00m\n\u001b[0;32m     40\u001b[0m     \u001b[39m#err += get_rmse(R_pred, R_test)\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m     \u001b[39mprint\u001b[39m( get_rmse(R_pred, R_test) )\n\u001b[0;32m     43\u001b[0m \u001b[39m#print(\"*** RMSE Error : ,\" + err / 5 )\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mMean number of iterations:\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m n_iter \u001b[39m/\u001b[39m \u001b[39m5\u001b[39m )\n",
      "Cell \u001b[1;32mIn [278], line 6\u001b[0m, in \u001b[0;36mget_rmse\u001b[1;34m(pred, actual)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_rmse\u001b[39m(pred, actual):\n\u001b[0;32m      4\u001b[0m     \u001b[39m#pred = pred[actual.nonzero()].flatten()     # Ignore nonzero terms\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     \u001b[39m#actual = actual[actual.nonzero()].flatten() # Ignore nonzero terms\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39msqrt(mean_squared_error(pred, actual))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_regression.py:442\u001b[0m, in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmean_squared_error\u001b[39m(\n\u001b[0;32m    383\u001b[0m     y_true, y_pred, \u001b[39m*\u001b[39m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, multioutput\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39muniform_average\u001b[39m\u001b[39m\"\u001b[39m, squared\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    384\u001b[0m ):\n\u001b[0;32m    385\u001b[0m     \u001b[39m\"\"\"Mean squared error regression loss.\u001b[39;00m\n\u001b[0;32m    386\u001b[0m \n\u001b[0;32m    387\u001b[0m \u001b[39m    Read more in the :ref:`User Guide <mean_squared_error>`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[39m    0.825...\u001b[39;00m\n\u001b[0;32m    441\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 442\u001b[0m     y_type, y_true, y_pred, multioutput \u001b[39m=\u001b[39m _check_reg_targets(\n\u001b[0;32m    443\u001b[0m         y_true, y_pred, multioutput\n\u001b[0;32m    444\u001b[0m     )\n\u001b[0;32m    445\u001b[0m     check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    446\u001b[0m     output_errors \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39maverage((y_true \u001b[39m-\u001b[39m y_pred) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, weights\u001b[39m=\u001b[39msample_weight)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_regression.py:100\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_reg_targets\u001b[39m(y_true, y_pred, multioutput, dtype\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnumeric\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     67\u001b[0m     \u001b[39m\"\"\"Check that y_true and y_pred belong to the same regression task.\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \n\u001b[0;32m     69\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[39m        correct keyword.\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 100\u001b[0m     check_consistent_length(y_true, y_pred)\n\u001b[0;32m    101\u001b[0m     y_true \u001b[39m=\u001b[39m check_array(y_true, ensure_2d\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[0;32m    102\u001b[0m     y_pred \u001b[39m=\u001b[39m check_array(y_pred, ensure_2d\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, dtype\u001b[39m=\u001b[39mdtype)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\validation.py:387\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    385\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[0;32m    386\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 387\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    388\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    389\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[0;32m    390\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [111, 110]"
     ]
    }
   ],
   "source": [
    "#RMSE for cross validation of n_fold models\n",
    "\n",
    "err = 0\n",
    "n_iter = 0\n",
    "#n_folds = 5\n",
    "#kf = 5\n",
    "\n",
    "#kf = KFold(6608, 5)\n",
    "#n_splits = 5\n",
    "#kf = KFold(n_splits = n_splits, shuffle = True, random_state = 42)\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=5, random_state=None, shuffle=True)\n",
    "for train_index, test_index in kf.split(X_test):  \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Converting sparse array to dense array\n",
    "    R_train = ConvertToDense_new(y_train, X_train[:,0], X_train[:,1])\n",
    "    R_test = ConvertToDense_new(y_test, X_test[:,0], X_test[:,1])\n",
    "\n",
    "\n",
    "    # Training (matrix factorization)\n",
    "    t0 = time.time()\n",
    "    estimator.fit(R_train)  \n",
    "    Theta = estimator.transform(R_train)       # user features\n",
    "    M = estimator.components_.T                # item features\n",
    "    print(  time.time() - t0  )\n",
    "    n_iter += estimator.n_iter_ \n",
    "\n",
    "    # Making the predictions\n",
    "    R_pred = M.dot(Theta.T)\n",
    "    R_pred = R_pred.T      \n",
    "    \n",
    "    # Clipping values                                                    \n",
    "    #R_pred[R_pred > 5] = 5.           # clips ratings above 5             \n",
    "    #R_pred[R_pred < 1] = 1.           # clips ratings below 1\n",
    "\n",
    "    # Computing the error on the validation set \n",
    "    #err += get_rmse(R_pred, R_test)\n",
    "    print( get_rmse(R_pred, R_test) )\n",
    "    \n",
    "#print(\"*** RMSE Error : ,\" + err / 5 )\n",
    "print(\"Mean number of iterations:\" + n_iter / 5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#cv = ShuffleSplit(X_train.shape[0], n_iter=5, test_size=0.20, random_state=0)  \n",
    "\n",
    "cv = ShuffleSplit(n_splits = 10,  test_size = 0.2, random_state = 0)      \n",
    "# 5-fold sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 2586 is out of bounds for axis 0 with size 1058",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [300], line 31\u001b[0m\n\u001b[0;32m     28\u001b[0m cv\u001b[39m.\u001b[39mget_n_splits(X,y)\n\u001b[0;32m     29\u001b[0m \u001b[39mfor\u001b[39;00m train_index, test_index \u001b[39min\u001b[39;00m cv\u001b[39m.\u001b[39msplit(X, y):  \n\u001b[1;32m---> 31\u001b[0m     X_train_cv, X_test_cv \u001b[39m=\u001b[39m X_train[train_index], X_train[test_index]\n\u001b[0;32m     32\u001b[0m     y_train_cv, y_test_cv \u001b[39m=\u001b[39m y_train[train_index], y_train[test_index]\n\u001b[0;32m     34\u001b[0m     \u001b[39m# Converting sparse array to dense array\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 2586 is out of bounds for axis 0 with size 1058"
     ]
    }
   ],
   "source": [
    "###Grid search\n",
    "\n",
    "param =        {\n",
    "                    'n_components' : [15, 20, 25],\n",
    "                    'alpha' : [0.001, 0.01, 0.1],\n",
    "                    'l1_ratio' : [0], \n",
    "                    'max_iter' : [15, 20, 25]\n",
    "                }\n",
    "\n",
    "# Keep track of RMSE and parameters\n",
    "grid_search = pd.DataFrame([[0, 0, 0, 0, 0]])\n",
    "grid_search.columns = ['n_components', 'alpha', 'l1_ratio', 'max_iter'] + ['RMSE']\n",
    "\n",
    "# nb of folds in ShuffleSplit CV\n",
    "n_folds = 5      \n",
    "i = 0\n",
    "\n",
    "# Performing the Grid search\n",
    "for n_components in param['n_components']:\n",
    "    for alpha in param['alpha']:\n",
    "        for l1_ratio in param['l1_ratio']:\n",
    "            for max_iter in param['max_iter']:\n",
    "\n",
    "                err = 0\n",
    "                n_iter = 0\n",
    "                #print('Search'),print(str(i)), print('/'), print(str(3 ** 3 - 1))\n",
    "                \n",
    "                cv.get_n_splits(X,y)\n",
    "                for train_index, test_index in cv.split(X, y):  \n",
    "    \n",
    "                    X_train_cv, X_test_cv = X_train[train_index], X_train[test_index]\n",
    "                    y_train_cv, y_test_cv = y_train[train_index], y_train[test_index]\n",
    "    \n",
    "                    # Converting sparse array to dense array\n",
    "                    \n",
    "                    R_train = ConvertToDense_new(y_train, X_train[:,0], X_train[:,1])\n",
    "                    R_test = ConvertToDense_new(y_test, X_test[:,0], X_test[:,1])\n",
    "\n",
    "                    # updating the parameters\n",
    "                    parametersNMF = {\n",
    "                    'n_components' : n_components,\n",
    "                    'init' : 'random', \n",
    "                    'random_state' : 0, \n",
    "                    'alpha' : alpha,\n",
    "                    'l1_ratio' : l1_ratio,\n",
    "                    'max_iter' : max_iter}\n",
    "                    estimator = NMF(**parametersNMF)\n",
    "                \n",
    "                    # Training (matrix factorization)\n",
    "                    t0 = time.time()\n",
    "                    estimator.fit(R_train)  \n",
    "                    Theta = estimator.transform(R_train)       # user features\n",
    "                    M = estimator.components_.T                # item features\n",
    "                    #print \"Fit in %0.3fs\" % (time.time() - t0)\n",
    "                    n_iter += estimator.n_iter_ \n",
    "\n",
    "                    # Making the predictions\n",
    "                    R_pred = M.dot(Theta.T).T\n",
    "                    \n",
    "                    # Clipping values                                                    \n",
    "                    #R_pred[R_pred > 5] = 5.           # clips ratings above 5             \n",
    "                    #R_pred[R_pred < 1] = 1.           # clips ratings below 1\n",
    "\n",
    "                    # Computing the error on the validation set \n",
    "                    err += get_rmse(R_pred, R_test)\n",
    "    \n",
    "                #print \"RMSE Error : \", err / n_folds\n",
    "                grid_search.loc[i] = [n_components, alpha, l1_ratio, max_iter, err / n_folds]\n",
    "                print(grid_search.loc[i].tolist()), \n",
    "                print(\"Mean number of iterations:\"),\n",
    "                print( n_iter / n_folds)\n",
    "                i += 1\n",
    "\n",
    "best_params = grid_search.sort_values('RMSE')[:1]\n",
    "print('*** best params ***')\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametersNMF_opt = {\n",
    "                    'n_components' : 20,     # number of latent factors\n",
    "                    'init' : 'random', \n",
    "                    'random_state' : 0, \n",
    "                    'alpha' : 0.01,          # regularization term\n",
    "                    'l1_ratio' : 0,          # set regularization = L2 \n",
    "                    'max_iter' : 15\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE test: 3.319155635313933\n"
     ]
    }
   ],
   "source": [
    "estimator = NMF(**parametersNMF_opt)\n",
    "                \n",
    "# Training (matrix factorization)\n",
    "estimator.fit(R_train)  \n",
    "Theta = estimator.transform(R_train)       # user features\n",
    "M = estimator.components_.T                # item features\n",
    "\n",
    "# Making the predictions\n",
    "R_pred = M.dot(Theta.T).T\n",
    "                    \n",
    "# Clipping values                                                    \n",
    "#R_pred[R_pred > 5] = 5.           # clips ratings above 5             \n",
    "#R_pred[R_pred < 1] = 1.           # clips ratings below 1\n",
    "\n",
    "# Computing the error on the test set \n",
    "print('RMSE test:', get_rmse(R_pred, R_test) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.04842243],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.08330314],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.00392446],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.0498742 ]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=int64))"
      ]
     },
     "execution_count": 568,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_pred, R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##2.7 Train the final model on whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = NMF(**parametersNMF_opt)\n",
    "                \n",
    "# Training (matrix factorization)\n",
    "estimator.fit(R)  \n",
    "Theta = estimator.transform(R)            # user features\n",
    "M = estimator.components_.T               # item features\n",
    "\n",
    "# Making the predictions\n",
    "R_pred = M.dot(Theta.T).T\n",
    "                    \n",
    "# Clipping values                                                    \n",
    "#R_pred[R_pred > 5] = 5.           # clips ratings above 5             \n",
    "#R_pred[R_pred < 1] = 1.           # clips ratings below 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_all_df = pd.DataFrame(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((610, 2698), (610, 2698))"
      ]
     },
     "execution_count": 570,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R.shape, R_pred.shape\n",
    "\n",
    "#R_df = pd.DataFrame(R)\n",
    "#R_Pred =pd.DataFrame(R_pred)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_pred_df_all = pd.DataFrame(R_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_df = pd.DataFrame(R).iloc[10, :] \n",
    "R_pred_df = pd.DataFrame(R_pred).iloc[10, :] \n",
    "\n",
    "#R_pred_df =pd.DataFrame(R_pred)\n",
    "#R_df = pd.DataFrame(R)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [],
   "source": [
    "#movies_list = movies[['title', 'movieId']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Congo (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Eye for an Eye (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>How to Make an American Quilt (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Mr. Wonderful (1993)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Dolores Claiborne (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>Powder (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>Nadja (1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.0</td>\n",
       "      <td>Priest (1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.0</td>\n",
       "      <td>Up Close and Personal (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.0</td>\n",
       "      <td>Forbidden Planet (1956)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                 title\n",
       "0   1.0                          Congo (1995)\n",
       "1   2.0                 Eye for an Eye (1996)\n",
       "2   3.0  How to Make an American Quilt (1995)\n",
       "3   4.0                  Mr. Wonderful (1993)\n",
       "4   5.0              Dolores Claiborne (1995)\n",
       "5   6.0                         Powder (1995)\n",
       "6   7.0                          Nadja (1994)\n",
       "7   8.0                         Priest (1994)\n",
       "8   9.0          Up Close and Personal (1996)\n",
       "9  10.0               Forbidden Planet (1956)"
      ]
     },
     "execution_count": 613,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "R_df = pd.DataFrame(R).iloc[10, :] \n",
    "R_pred_df = pd.DataFrame(R_pred).iloc[10, :] \n",
    "\n",
    "recList = pd.DataFrame(pd.merge(R_pred_df, R_df , left_index=True, right_index=True)  )\n",
    "\n",
    "# Sort ascending order\n",
    "recList.sort_values(recList.columns[0], ascending=False, inplace=True)\n",
    "\n",
    "###remove movies already viewed by the user\n",
    "recList.drop(recList[recList.iloc[:,1] > 0].index, inplace=True)\n",
    "\n",
    "###drop exisitng film rated column\n",
    "#recList.drop(recList.iloc[:,1].index, inplace=True)\n",
    "recList=recList.drop(recList.columns[1], axis=1)\n",
    "\n",
    "##trim predicted ratins when revie > 0\n",
    "recList.drop(recList[recList.iloc[:,0] == 0].index, inplace=True)\n",
    "\n",
    "###create movieid column in rec list using the index\n",
    "recList['movieId'] = recList.index\n",
    "\n",
    "##creat full movie title list from original movies df\n",
    "movies_list = movies[['title', 'movieId']]\n",
    "\n",
    "##join  recList10 with the 'movie_names' dataframe to insert the Movie titles\n",
    "recList =  pd.merge(recList, movies_list, left_on=['movieId'], right_on=['movieId'], how='inner')\n",
    "\n",
    "#top 10\n",
    "recList10 = recList.head(10)\n",
    "recList10.rename(columns={recList10.columns[0]: 'Prediction'},inplace=True)\n",
    "recList10['Rank'] = recList10['Prediction'].rank(ascending=False)\n",
    "\n",
    "recList10[['Rank','title']]\n",
    "\n",
    "#recList10\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(R), print(R_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the trained model to file\n",
    "with open('acW10_nmf_model_FIN.sav', 'wb') as f:\n",
    "    pickle.dump(estimator, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['title'].unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title    Georgia (1995)\n",
       "Name: 50, dtype: object"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_titles = pd.DataFrame(movies['title'])\n",
    "#movie_titles = movie_titles['title'].unique\n",
    "\n",
    "moviealter = pd.DataFrame(movie_titles).iloc[50,:] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###3.1 Item recommendation for an active user (given its rating history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_recommendation_activeuser(R, prediction, user_id, k=10):\n",
    "    '''\n",
    "    user_idx ...... select an active user\n",
    "    k  ............ number of movies to recommend\n",
    "    '''\n",
    "    \n",
    "    #rated_items_df_user = pd.DataFrame(R).iloc[user_idx, :]                 # get the list of actual ratings of user_idx (seen movies)\n",
    "    #user_prediction_df_user = pd.DataFrame(prediction).iloc[user_idx,:]     # get the list of predicted ratings of user_idx (unseen movies)\n",
    "    #reco_df = pd.concat([rated_items_df_user, user_prediction_df_user, movie_titles], axis=1)   # merge both lists with the movie's title\n",
    "    #reco_df.columns = ['rating','prediction','title']\n",
    "    \n",
    "\n",
    "    R_df = pd.DataFrame(R).iloc[user_id, :] \n",
    "    R_pred_df = pd.DataFrame(prediction).iloc[user_id, :] \n",
    "\n",
    "    recList = pd.DataFrame(pd.merge(R_pred_df, R_df , left_index=True, right_index=True)  )\n",
    "\n",
    "    # Sort ascending order\n",
    "    recList.sort_values(recList.columns[0], ascending=False, inplace=True)\n",
    "\n",
    "    ###remove movies already viewed by the user\n",
    "    recList.drop(recList[recList.iloc[:,1] > 0].index, inplace=True)\n",
    "\n",
    "    ###drop exisitng film rated column\n",
    "    #recList.drop(recList.iloc[:,1].index, inplace=True)\n",
    "    recList=recList.drop(recList.columns[1], axis=1)\n",
    "\n",
    "    ##trim predicted ratins when revie > 0\n",
    "    recList.drop(recList[recList.iloc[:,0] == 0].index, inplace=True)\n",
    "\n",
    "    ###create movieid column in rec list using the index\n",
    "    recList['movieId'] = recList.index\n",
    "\n",
    "    ##creat full movie title list from original movies df\n",
    "    movies_list = movies[['title', 'movieId']]\n",
    "\n",
    "    ##join  recList10 with the 'movie_names' dataframe to insert the Movie titles\n",
    "    recList =  pd.merge(recList, movies_list, left_on=['movieId'], right_on=['movieId'], how='inner')\n",
    "\n",
    "    #top  or top k recommendations\n",
    "    recList10 = recList.head(k)\n",
    "    recList10.rename(columns={recList10.columns[0]: 'Predictions'},inplace=True)\n",
    "    recList10['Rank'] = recList10['Predictions'].rank(ascending=False)\n",
    "\n",
    "    return recList10[['Rank','title']]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Vertigo (1958)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Powder (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Mr. Wonderful (1993)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Crumb (1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>It Takes Two (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>Before Sunrise (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>Money Train (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.0</td>\n",
       "      <td>Beautiful Girls (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.0</td>\n",
       "      <td>Eye for an Eye (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.0</td>\n",
       "      <td>Shanghai Triad (Yao a yao yao dao waipo qiao) ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                              title\n",
       "0   1.0                                     Vertigo (1958)\n",
       "1   2.0                                      Powder (1995)\n",
       "2   3.0                               Mr. Wonderful (1993)\n",
       "3   4.0                                       Crumb (1994)\n",
       "4   5.0                                It Takes Two (1995)\n",
       "5   6.0                              Before Sunrise (1995)\n",
       "6   7.0                                 Money Train (1995)\n",
       "7   8.0                             Beautiful Girls (1996)\n",
       "8   9.0                              Eye for an Eye (1996)\n",
       "9  10.0  Shanghai Triad (Yao a yao yao dao waipo qiao) ..."
      ]
     },
     "execution_count": 621,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_recommendation_activeuser(R, R_pred, user_id=50, k=10)\n",
    "#make_recommendation_activeuser(R, R_pred, user_idx=130, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####new user function\n",
    "query = {12: 4, 92: 5, 177: 4, 196: 5, 891: 4, 1128: 5, 1258: 5, 1320: 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([4, 5, 4, 5, 4, 5, 5, 4],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [12, 92, 177, 196, 891, 1128, 1258, 1320])"
      ]
     },
     "execution_count": 624,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = list(query.values())   # the ratings of the new user\n",
    "row_ind = [0]*len(data)       # we use just a single row 0 for this user \n",
    "col_ind = list(query.keys())  # the columns (=movieId) of the ratings\n",
    "data, row_ind, col_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2698"
      ]
     },
     "execution_count": 625,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x2698 sparse matrix of type '<class 'numpy.intc'>'\n",
       "\twith 8 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 626,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nuser_vec = csr_matrix((data, (row_ind, col_ind)), shape=(1, R.shape[1]))\n",
    "nuser_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<610x2698 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 6559 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 630,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###converrt dense R matric to sparse\n",
    "R_sp = csr_matrix(R)\n",
    "R_sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "violation: 1.0\n",
      "violation: 0.3628336098224234\n",
      "violation: 0.2655168124582823\n",
      "violation: 0.20760339045847945\n",
      "violation: 0.1632238280341509\n",
      "violation: 0.13096531918009907\n",
      "violation: 0.10838819683385183\n",
      "violation: 0.09108200531368006\n",
      "violation: 0.07734289138423955\n",
      "violation: 0.06672526167164686\n",
      "violation: 0.05879197356986169\n",
      "violation: 0.05296301754387636\n",
      "violation: 0.04855998393365482\n",
      "violation: 0.04524016886380106\n",
      "violation: 0.042795935866795934\n",
      "violation: 0.04116509976085029\n",
      "violation: 0.040198767480496146\n",
      "violation: 0.038699925411774805\n",
      "violation: 0.036670524812483805\n",
      "violation: 0.03426029804143876\n",
      "violation: 0.0318163969637116\n",
      "violation: 0.030902872242907307\n",
      "violation: 0.031031409364830058\n",
      "violation: 0.031409416264783795\n",
      "violation: 0.03015372932737926\n",
      "violation: 0.027910996362005742\n",
      "violation: 0.025568519647768247\n",
      "violation: 0.022662622013688984\n",
      "violation: 0.020566421202884325\n",
      "violation: 0.018894450893642695\n",
      "violation: 0.017537856756638118\n",
      "violation: 0.016582678738989103\n",
      "violation: 0.015170199472564054\n",
      "violation: 0.013949186779057038\n",
      "violation: 0.013082331099091968\n",
      "violation: 0.012404567809573603\n",
      "violation: 0.011851606747275655\n",
      "violation: 0.011472026668713439\n",
      "violation: 0.011184522964809629\n",
      "violation: 0.010895699023631262\n",
      "violation: 0.010686443120565749\n",
      "violation: 0.01037984703725336\n",
      "violation: 0.010070142005260727\n",
      "violation: 0.009748036743473942\n",
      "Converged at iteration 45\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NMF(init=&#x27;nndsvd&#x27;, max_iter=10000, n_components=20, tol=0.01, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NMF</label><div class=\"sk-toggleable__content\"><pre>NMF(init=&#x27;nndsvd&#x27;, max_iter=10000, n_components=20, tol=0.01, verbose=2)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "NMF(init='nndsvd', max_iter=10000, n_components=20, tol=0.01, verbose=2)"
      ]
     },
     "execution_count": 634,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###trian model 2 NMF\n",
    "\n",
    "\n",
    "model2 = NMF(n_components=20, init='nndsvd', max_iter=10000, tol=0.01, verbose=2)\n",
    "# fit it to the user-item rating matrix\n",
    "model2.fit(R_sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 2698)"
      ]
     },
     "execution_count": 635,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "violation: 1.0\n",
      "violation: 0.114924467454566\n",
      "violation: 0.008384397908123\n",
      "Converged at iteration 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((610, 20), (20, 2698))"
      ]
     },
     "execution_count": 636,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# user-'genre' matrix [611x55]\n",
    "P=model2.transform(R)\n",
    "# movie-'genre' matrix [55x168253]\n",
    "Q=model2.components_\n",
    "P.shape, Q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x2698 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 0 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 637,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# user with id 1: sparse format\n",
    "R_sp[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0.])"
      ]
     },
     "execution_count": 639,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# user with id 1: dense embedding\n",
    "P[1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.0253681 ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.03825445],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.00338201],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.03053722]])"
      ]
     },
     "execution_count": 640,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reconstructed matrix Rhat\n",
    "R_sp_hat = P.dot(Q)\n",
    "R_sp_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "violation: 1.0\n",
      "violation: 0.11492446745456598\n",
      "violation: 0.008384397908122983\n",
      "Converged at iteration 4\n"
     ]
    }
   ],
   "source": [
    "# R -> encoding -> P -> decoding -> Rhat (one-liner to get R_hat)\n",
    "R_sp_hat = model2.inverse_transform(model2.transform(R_sp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((610, 2698), (610, 2698))"
      ]
     },
     "execution_count": 643,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_sp.shape, R_sp_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174.6651357190336"
      ]
     },
     "execution_count": 644,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.reconstruction_err_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('nmf_recommenderM2.pkl', 'wb') as file:\n",
    "    pickle.dump(model2, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [],
   "source": [
    "##read the model back\n",
    "with open('nmf_recommenderM2.pkl', 'rb') as file:\n",
    "    model2 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{12: 4, 92: 5, 177: 4, 196: 5, 891: 4, 1128: 5, 1258: 5, 1320: 4}"
      ]
     },
     "execution_count": 647,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x2698 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 0 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 649,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_sp[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([4, 5, 4, 5, 4, 5, 5, 4],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [12, 92, 177, 196, 891, 1128, 1258, 1320])"
      ]
     },
     "execution_count": 650,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Construct a user vector\n",
    "data = list(query.values())   # the ratings of the new user\n",
    "row_ind = [0]*len(data)       # we use just a single row 0 for this user \n",
    "col_ind = list(query.keys())  # the columns (=movieId) of the ratings\n",
    "data, row_ind, col_ind\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x2698 sparse matrix of type '<class 'numpy.intc'>'\n",
       "\twith 8 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 651,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new user vector: needs to have the same format as the training data\n",
    "\n",
    "n_user_vec = csr_matrix((data, (row_ind, col_ind)), shape=(1, R_sp.shape[1]))\n",
    "n_user_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "violation: 1.0\n",
      "violation: 0.04816419115662636\n",
      "violation: 0.00023135885686553767\n",
      "Converged at iteration 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0       0.000000\n",
       "1       0.000000\n",
       "2       0.000000\n",
       "3       0.000000\n",
       "4       0.000000\n",
       "          ...   \n",
       "2693    0.000000\n",
       "2694    0.000000\n",
       "2695    0.000000\n",
       "2696    0.000000\n",
       "2697    0.002773\n",
       "Length: 2698, dtype: float64"
      ]
     },
     "execution_count": 652,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate model2 score\n",
    "\n",
    "scores = model2.inverse_transform(model2.transform(n_user_vec))\n",
    "\n",
    "# convert to a pandas series\n",
    "scores = pd.Series(scores[0])\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([12, 92, 177, 196, 891, 1128, 1258, 1320])"
      ]
     },
     "execution_count": 653,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [],
   "source": [
    "# give a zero score to movies the user has allready seen\n",
    "scores[query.keys()] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61      0.166956\n",
       "140     0.142244\n",
       "94      0.138527\n",
       "167     0.107294\n",
       "111     0.105264\n",
       "          ...   \n",
       "1014    0.000000\n",
       "1015    0.000000\n",
       "1016    0.000000\n",
       "1017    0.000000\n",
       "1349    0.000000\n",
       "Length: 2698, dtype: float64"
      ]
     },
     "execution_count": 655,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sort scores\n",
    "scores = scores.sort_values(ascending=False)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([61, 140, 94, 167, 111, 134, 35, 276, 30, 75], dtype='int64')"
      ]
     },
     "execution_count": 656,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the movieIds of the top 10 entries\n",
    "recommendations = scores.head(10).index\n",
    "recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'movieId'], dtype='object')"
      ]
     },
     "execution_count": 663,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_list.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 670,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [],
   "source": [
    "#movies_list.set_index('movieId', infile= True)\n",
    "#movies_list = movies_list.set_index('movieId')\n",
    "movies_list['movieId'] = movies_list.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'movieId'], dtype='object')"
      ]
     },
     "execution_count": 680,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_list.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [],
   "source": [
    "#movies_list.set_index('movieId').loc[recommendations]\n",
    "\n",
    "\n",
    "#movies_list = movies_list.set_index('movieId')\n",
    "recs = pd.DataFrame(recommendations)\n",
    "recs.rename(columns={recs.columns[0]: 'movieId'},inplace=True)\n",
    "\n",
    "recs= pd.merge(recs, movies_list, left_on=['movieId'], right_on=movies_list['movieId'], how='inner')\n",
    "recs[['title']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Eye for an Eye (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Up Close and Personal (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beautiful Girls (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Taxi Driver (1976)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Milk Money (1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Shanghai Triad (Yao a yao yao dao waipo qiao) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Big Bully (1996)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title\n",
       "0                              Eye for an Eye (1996)\n",
       "1                       Up Close and Personal (1996)\n",
       "2                             Beautiful Girls (1996)\n",
       "3                                 Taxi Driver (1976)\n",
       "4                                  Milk Money (1994)\n",
       "5  Shanghai Triad (Yao a yao yao dao waipo qiao) ...\n",
       "6                                   Big Bully (1996)"
      ]
     },
     "execution_count": 686,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recs[['title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{12: 4, 92: 5, 177: 4, 196: 5, 891: 4, 1128: 5, 1258: 5, 1320: 4}"
      ]
     },
     "execution_count": 665,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collaborative filtering = look at ratings only!\n",
    "def new_recommend_nmf(query, model, ratings, k=10):\n",
    "    \"\"\"\n",
    "    Filters and recommends the top k movies for any given input query based on a trained NMF model. \n",
    "    Returns a list of k movie ids.\n",
    "    \"\"\"\n",
    "   #Construct a user vector\n",
    "    data = list(query.values())   # the ratings of the new user\n",
    "    row_ind = [0]*len(data)       # we use just a single row 0 for this user \n",
    "    col_ind = list(query.keys())  # the columns (=movieId) of the ratings\n",
    "    data, row_ind, col_ind\n",
    "    \n",
    "    # construct a user vector\n",
    "    # new user vector: needs to have the same format as the training data\n",
    "\n",
    "    n_user_vec = csr_matrix((data, (row_ind, col_ind)), shape=(1, R_sp.shape[1]))\n",
    "    n_user_vec\n",
    "   \n",
    "    # 2. scoring\n",
    "    \n",
    "    #calculate model2 score\n",
    "    scores = model2.inverse_transform(model2.transform(n_user_vec))\n",
    "    # convert to a pandas series\n",
    "    scores = pd.Series(scores[0])\n",
    "    scores = scores.sort_values(ascending=False)\n",
    "  \n",
    "    \n",
    "    # 3. ranking\n",
    "    \n",
    "    # filter out movies allready seen by the user\n",
    "    # give a zero score to movies the user has allready seen\n",
    "    scores[query.keys()] = 0\n",
    "    # return the top-k highst rated movie ids or titles\n",
    "    recommendations = scores.head(k).index\n",
    "    \n",
    "\n",
    "    #movies_list = movies_list.set_index('movieId')\n",
    "    recs = pd.DataFrame(recommendations)\n",
    "    recs.rename(columns={recs.columns[0]: 'movieId'},inplace=True)\n",
    "\n",
    "    recs= pd.merge(recs, movies_list, left_on=['movieId'], right_on=movies_list['movieId'], how='inner')\n",
    "    return recs[['title']]\n",
    "#movies.set_index('movieId').loc[recommendations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "violation: 1.0\n",
      "violation: 0.04816419115662636\n",
      "violation: 0.00023135885686553767\n",
      "Converged at iteration 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Eye for an Eye (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Up Close and Personal (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beautiful Girls (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Taxi Driver (1976)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Milk Money (1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Shanghai Triad (Yao a yao yao dao waipo qiao) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Big Bully (1996)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title\n",
       "0                              Eye for an Eye (1996)\n",
       "1                       Up Close and Personal (1996)\n",
       "2                             Beautiful Girls (1996)\n",
       "3                                 Taxi Driver (1976)\n",
       "4                                  Milk Money (1994)\n",
       "5  Shanghai Triad (Yao a yao yao dao waipo qiao) ...\n",
       "6                                   Big Bully (1996)"
      ]
     },
     "execution_count": 692,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_recommend_nmf(query, model2, ratings, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f09ff2775d7407c2cf5d3467f8a20afd6c3e47667e08536d937bcbe3f94dac6a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
