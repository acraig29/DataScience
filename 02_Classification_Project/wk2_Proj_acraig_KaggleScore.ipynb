{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This is Part 4 of 4 Code files for Week 2 Titanic Modelling assignment\n",
    "### Create the ypreds file for the Kaggle competition using my Random Forrest model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "#wd = os.getcwd()\n",
    "wd = 'C:/Users/lisbo/OneDrive/AC Career/Spiced_Academy_DS/spiced_projects/cascabel-curve-student-code/week_02/data/'\n",
    "\n",
    "df_Ktest = pd.read_csv(wd + 'test.csv', index_col=0, header =0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Import the complete Titanic Training dataset from Kaggle ad fit a new and better  \n",
    "Random forrest model and then generate better Ypred , do not test/train split buy instead use \n",
    "the Kaggle test data to test the model to produce the ypreds  \"\"\"\n",
    "\n",
    "wd = 'C:/Users/lisbo/OneDrive/AC Career/Spiced_Academy_DS/spiced_projects/cascabel-curve-student-code/week_02/data/'\n",
    "\n",
    "df_K_rfmod = pd.read_csv(wd + 'train.csv', index_col=0, header =0)\n",
    "df_K_rfmod = df_K_rfmod.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#import the Random Forrest Model from file 3 \n",
    "%store -r rf_mod\n",
    "rf_mod = rf_mod\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', criterion='entropy',\n",
       "                       max_depth=7, n_estimators=15)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced', max_iter=10000)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import the Logistic Model from file 2\n",
    "%store -r lg_mod\n",
    "lg_mod = lg_mod\n",
    "\n",
    "lg_mod "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced', max_iter=10000)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg_mod "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Usig KAGGLE TEST DATASET to create Predictors file for the Kaggle Titanic competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Passs the Kaggle test dataset 'df_Ktest' through the same data feature engineering as my \n",
    "##origninal Traiing dataset in order to prepare it properly for prediction generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare',\n",
       "       'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Ktest.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining NaN values: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##assess the average ages of passengers based on their Sex and Pclass\n",
    "\n",
    "df_Ktest_byPclass = df_Ktest.groupby(by=['Sex','Pclass'])\n",
    "df_Ktest_byPclass = df_Ktest.groupby(by=['Sex','Pclass'])\n",
    "df_Ktest_byPclass['Age'].mean()\n",
    "#df_Ktest_byPclass['Age_i'].mean() \n",
    "\n",
    "#Impute the average age based on the average age by 'Sex' and 'Pclass'\n",
    "df_Ktest_byPclass = df_Ktest.groupby(by=['Sex','Pclass'])\n",
    "df_Ktest_byPclass['Age'].mean()\n",
    "\n",
    "df_Ktest['C1'] = np.where(np.isnan(df_Ktest['Age'].values),1,0) \n",
    "\n",
    "def new_val(df_Ktest):    \n",
    "    if  (df_Ktest['C1'] == 1 ) & (df_Ktest['Sex'] == 'female' ) & (df_Ktest['Pclass'] == 1)  :\n",
    "        return 35\n",
    "    elif (df_Ktest['C1'] == 1) & (df_Ktest['Sex'] == 'female')  & (df_Ktest['Pclass'] == 2)  :\n",
    "        return 29\n",
    "    elif (df_Ktest['C1'] == 1) & (df_Ktest['Sex'] == 'female' ) & (df_Ktest['Pclass'] == 3)  :\n",
    "        return 21\n",
    "    elif (df_Ktest['C1'] == 1) & (df_Ktest['Sex'] == 'male')  & (df_Ktest['Pclass'] == 1)  :\n",
    "        return 4\n",
    "    elif (df_Ktest['C1'] == 1) & (df_Ktest['Sex'] == 'male')  & (df_Ktest['Pclass'] == 2)   :\n",
    "        return 31   \n",
    "    elif (df_Ktest['C1'] == 1) & (df_Ktest['Sex'] == 'male')  & (df_Ktest['Pclass'] == 3 )  :\n",
    "        return 27 \n",
    "    else:\n",
    "        return df_Ktest['Age']\n",
    "\n",
    "df_Ktest['Age_i'] = df_Ktest.apply(new_val, axis = 1)\n",
    "\n",
    "###create Age categoricla variable\n",
    "df_Ktest['Age_i'] = df_Ktest['Age_i']\n",
    "#.astype(int)\n",
    "\n",
    "def new_acat(df_Ktest):    \n",
    "    if  (df_Ktest['Age_i'] <= 12 )  :\n",
    "        return 'Child'\n",
    "    elif (df_Ktest['Age_i'] > 12) & (df_Ktest['Age_i'] <= 19)  :\n",
    "        return 'Teenager'\n",
    "    elif (df_Ktest['Age_i'] > 19) & (df_Ktest['Age_i'] <= 35 )  :\n",
    "        return 'Young_Adults'\n",
    "    elif (df_Ktest['Age_i'] > 35) & (df_Ktest['Age_i'] <= 60 )  :\n",
    "        return 'Middle_Aged'\n",
    "    elif (df_Ktest['Age_i'] > 60)   :\n",
    "        return 'Elderly'   \n",
    "\n",
    "df_Ktest['Age_Cat'] = df_Ktest.apply(new_acat, axis = 1)\n",
    "\n",
    "##convert new age categories into dummy variables   \n",
    "age_dums = pd.get_dummies(df_Ktest['Age_Cat'])\n",
    "df_Ktest=df_Ktest.join(age_dums, lsuffix=\"_left\", rsuffix=\"_right\")\n",
    "\n",
    "###\n",
    "##create numeric Age categorical variable for he Randow Forrest data\n",
    "df_Ktest['Age_Cat_i'] = df_Ktest['Age_Cat'].map({'Child':  0, 'Teenager':  1, 'Young_Adults': 2, 'Middle_Aged':  3, 'Elderly':  4, 'Deck_F': 5 })\n",
    "\n",
    "#Extract the titles from the name field to \n",
    "import re #import the regular expresiona package\n",
    "\n",
    "def create_title(name):\n",
    "    \n",
    "    # try to find the pattern, returns None if nothing is found\n",
    "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    \n",
    "    # return the title if exists\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    \n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "# create the new title column\n",
    "df_Ktest['Title'] = df_Ktest['Name'].apply(create_title)\n",
    "\n",
    "#group and rename the less frequent Titles into a 'RareTitle' categrory value:\n",
    "#Rename the followin titles:\n",
    "\n",
    "replacements = {\n",
    "   'Title': {\n",
    "    'Dr': 'RareTitle', \n",
    "    'Major': 'RareTitle', \n",
    "    'Col': 'RareTitle', \n",
    "    'Mile': 'RareTitle', \n",
    "    'Capt': 'RareTitle', \n",
    "    'Ms': 'RareTitle', \n",
    "    'Jonkheer': 'RareTitle', \n",
    "    'Don': 'RareTitle', \n",
    "    'Sir': 'RareTitle', \n",
    "    'Lady': 'RareTitle',\n",
    "    'Countess': 'RareTitle',\n",
    "    'M': 'RareTitle',\n",
    "    'Mme': 'RareTitle',\n",
    "    'Rev': 'RareTitle',\n",
    "    'Mlle': 'RareTitle'}\n",
    "}\n",
    "\n",
    "df_Ktest.replace(replacements,  inplace=True)\n",
    "\n",
    "df_Ktest['Title'].unique()\n",
    "df_Ktest['Title'].value_counts()\n",
    "#convert the 'Title' column into a binary dummy set of variables for each unique categoy:\n",
    "#'Mr', 'Mrs', 'Miss', 'Master', 'RareTitle', 'Rev', 'Mlle'\n",
    "\n",
    "title_dums = pd.get_dummies(df_Ktest['Title'])\n",
    "df_Ktest=df_Ktest.join(title_dums, lsuffix=\"_left\", rsuffix=\"_right\")\n",
    "\n",
    "#also create a numeric Title_cat column for the Randowm Forrest Model:\n",
    "\n",
    "def title_acat(df_Ktest):    \n",
    "    if  (df_Ktest['Title'] == 'Mr' )  :\n",
    "        return 0\n",
    "    elif (df_Ktest['Title'] == 'Mrs')   :\n",
    "        return 1\n",
    "    elif (df_Ktest['Title'] == 'Miss')  :\n",
    "        return 2\n",
    "    elif (df_Ktest['Title'] == 'Master')   :\n",
    "        return 3\n",
    "    elif (df_Ktest['Title'] == 'RareTitle')   :\n",
    "        return 4   \n",
    "\n",
    "df_Ktest['Title_Cat'] = df_Ktest.apply(title_acat, axis = 1)\n",
    "#.astype(int)\n",
    "\n",
    "################################################\n",
    "\n",
    "\n",
    "###Fare variable\n",
    "# Import libraries\n",
    "\n",
    "\n",
    "###create  new Fare categorical variable\n",
    "\n",
    "def new_fcat(df_Ktest):    \n",
    "    if  (df_Ktest['Fare'] < 10 )  :\n",
    "        return 'Fare_lt10'\n",
    "    elif (df_Ktest['Fare'] >= 10) & (df_Ktest['Fare'] <= 25)  :\n",
    "        return 'Fare_btw_10_25'\n",
    "    elif (df_Ktest['Fare'] > 25) & (df_Ktest['Fare'] <= 50 )  :\n",
    "        return 'Fare_mt25_50'\n",
    "    elif (df_Ktest['Fare'] > 50) & (df_Ktest['Fare'] <= 100 )  :\n",
    "        return 'Fare_mt50_100'\n",
    "    elif (df_Ktest['Fare'] > 100)   :\n",
    "        return 'Fare_mt100'   \n",
    "\n",
    "df_Ktest['Fare_Cat'] = df_Ktest.apply(new_fcat, axis = 1)\n",
    "\n",
    "##make numeric 'Fare_Cat' column for Random Forrest model\n",
    "df_Ktest['Fare_Cat'] = df_Ktest.apply(new_fcat, axis = 1)\n",
    "\n",
    "df_Ktest['Fare_Cat_i'] = df_Ktest['Fare_Cat'].replace(['Fare_lt10', 'Fare_btw_10_25', 'Fare_mt25_50','Fare_mt50_100','Fare_mt100'],\n",
    "                        [0, 1,2,3,4])\n",
    "df_Ktest['Fare_Cat_i'] = df_Ktest['Fare_Cat_i']\n",
    "#.astype(str)\n",
    "\n",
    "#create dummy variable for Fare variable\n",
    "\n",
    "df_Ktest['Fare_Cat'].unique()\n",
    "df_Ktest['Fare_Cat'].value_counts()\n",
    "\n",
    "fare_dums = pd.get_dummies(df_Ktest['Fare_Cat'])\n",
    "df_Ktest=df_Ktest.join(fare_dums, lsuffix=\"_left\", rsuffix=\"_right\")\n",
    "\n",
    "# Replace ['Embarked'] column NaN values with 'S' the most common value\n",
    "df_Ktest['Embarked'] = df_Ktest['Embarked'].fillna('S')\n",
    "# check if all values have been replaced\n",
    "print(\"Remaining NaN values: {}\".format(df_Ktest['Embarked'].isnull().sum()))\n",
    "\n",
    "# convert 'Sex' and 'Embarked' into numeric variables for the model\n",
    "# female equals 0 and male equals 1 in the sex column\n",
    "df_Ktest['Sex'] =  df_Ktest['Sex'].map({'female': 0, 'male': 1})\n",
    "\n",
    "# C = 0, Q = 1, S = 2 in the embarked column\n",
    "df_Ktest['Embarked'] = df_Ktest['Embarked'].map({'C':  0, 'Q':  1, 'S': 2})\n",
    "\n",
    "##Create a 'Deck' variable from the Cabin variable\n",
    "import re #regex library for character search\n",
    "\n",
    "deck = {\"A\": \"Deck_A\", \"B\": \"Deck_B\", \"C\": \"Deck_C\", \"D\": \"Deck_D\", \"E\": \"Deck_E\", \"F\": \"Deck_F\", \"G\": \"Deck_G\", \"U\": \"U\"}\n",
    "\n",
    "df_Ktest['Cabin'] = df_Ktest['Cabin'].fillna(\"U0\")\n",
    "df_Ktest['Deck'] = df_Ktest['Cabin'].map(lambda x: re.compile(\"([a-zA-Z]+)\").search(x).group())\n",
    "df_Ktest['Deck'] = df_Ktest['Deck'].map(deck)\n",
    "df_Ktest['Deck'] = df_Ktest['Deck'].fillna(0) ##replace all the missing values with a 0\n",
    "df_Ktest['Deck'] = df_Ktest['Deck'].astype(str)\n",
    "\n",
    "##create 'Deck' dummies variable for the Logistic regression model\n",
    "Deck_dums = pd.get_dummies(df_Ktest['Deck'])\n",
    "df_Ktest=df_Ktest.join(Deck_dums, lsuffix=\"_left\", rsuffix=\"_right\")\n",
    "\n",
    "##create numeric categorical variable for he Randow Forrest data\n",
    "df_Ktest['Deck'] = df_Ktest['Deck'].map({'Deck_A':  0, 'Deck_B':  1, 'Deck_C': 2, 'Deck_D':  3, 'Deck_E':  4, 'Deck_F': 5,  'Deck_G':  6, 'U':  7    })\n",
    "\n",
    "#df_Ktest.drop([df_Ktest.index[339]], inplace = True)\n",
    "#df_Ktest.drop(['0'], axis=1, inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Ktest2 = df_Ktest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select only relevant columns from the Kaggle test dataset for the Random Forrest Model:\n",
    "df_Ktest.drop([ 'Name','Age', 'Age_Cat', 'Ticket', 'Fare', 'Cabin', 'C1', 'Age_i','Title', 'Fare_Cat','Child', 'Elderly', 'Middle_Aged', 'Teenager','Young_Adults', 'Title', 'Master', 'Miss', 'Mr', 'Mrs', 'RareTitle','Fare_Cat','Fare_btw_10_25', 'Fare_lt10','Fare_mt100', 'Fare_mt25_50', 'Fare_mt50_100', \n",
    " 'Deck_A','Deck_B', 'Deck_C', 'Deck_D', 'Deck_E', 'Deck_F', 'Deck_G', 'U' ], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "##manaully tidy up the df_Ktest dataset\n",
    "#these fixes are minor bugs from the feature engineering stage that need a manual solution\n",
    "\n",
    "#df_Ktest.info()\n",
    "df_Ktest.drop(['Dona'], axis=1, inplace=True)\n",
    "df_Ktest['Fare_Cat_i'] = df_Ktest['Fare_Cat_i'].fillna(0)\n",
    "df_Ktest['Title_Cat'] = df_Ktest['Title_Cat'].fillna(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_predictions = rf_mod.predict(df_Ktest)\n",
    "df_Kpred = pd.DataFrame(K_predictions, index=df_Ktest.index, columns=['Survived'])\n",
    "\n",
    "df_Kpred.to_csv(r'Kaggle_Predictions3.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
       "       1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1,\n",
       "       1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "####ENd OF PROJECT ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "###use the logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Name' 'Age' 'Age_Cat' 'Ticket' 'Fare' 'Cabin' 'C1' 'Age_i' 'Title'\\n 'Fare_Cat' 'Child' 'Elderly' 'Middle_Aged' 'Teenager' 'Young_Adults'\\n 'Title' 'Master' 'Miss' 'Mr' 'Mrs' 'RareTitle' 'Fare_Cat'\\n 'Fare_btw_10_25' 'Fare_lt10' 'Fare_mt100' 'Fare_mt25_50' 'Fare_mt50_100'\\n 'Deck_A' 'Deck_B' 'Deck_C' 'Deck_D' 'Deck_E' 'Deck_F' 'Deck_G' 'U'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\temp\\ipykernel_17872\\1370679657.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Select only relevant columns from the Kaggle test dataset for the Random Forrest Model:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m df_Ktest2 = df_Ktest2.drop([ 'Name','Age', 'Age_Cat', 'Ticket', 'Fare', 'Cabin', 'C1', 'Age_i','Title', 'Fare_Cat','Child', 'Elderly', 'Middle_Aged', 'Teenager','Young_Adults', 'Title', 'Master', 'Miss', 'Mr', 'Mrs', 'RareTitle','Fare_Cat','Fare_btw_10_25', 'Fare_lt10','Fare_mt100', 'Fare_mt25_50', 'Fare_mt50_100', \n\u001b[1;32m----> 3\u001b[1;33m  'Deck_A','Deck_B', 'Deck_C', 'Deck_D', 'Deck_E', 'Deck_F', 'Deck_G', 'U' ], axis=1, inplace=True)\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\lisbo\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4313\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4314\u001b[0m             \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4315\u001b[1;33m             \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4316\u001b[0m         )\n\u001b[0;32m   4317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\lisbo\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4151\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4152\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4153\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4155\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\lisbo\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   4186\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4187\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4188\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4189\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\lisbo\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   5589\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5590\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5591\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5592\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5593\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Name' 'Age' 'Age_Cat' 'Ticket' 'Fare' 'Cabin' 'C1' 'Age_i' 'Title'\\n 'Fare_Cat' 'Child' 'Elderly' 'Middle_Aged' 'Teenager' 'Young_Adults'\\n 'Title' 'Master' 'Miss' 'Mr' 'Mrs' 'RareTitle' 'Fare_Cat'\\n 'Fare_btw_10_25' 'Fare_lt10' 'Fare_mt100' 'Fare_mt25_50' 'Fare_mt50_100'\\n 'Deck_A' 'Deck_B' 'Deck_C' 'Deck_D' 'Deck_E' 'Deck_F' 'Deck_G' 'U'] not found in axis\""
     ]
    }
   ],
   "source": [
    "#Select only relevant columns from the Kaggle test dataset for the Random Forrest Model:\n",
    "df_Ktest2 = df_Ktest2.drop([ 'Name','Age', 'Age_Cat', 'Ticket', 'Fare', 'Cabin', 'C1', 'Age_i','Title', 'Fare_Cat','Child', 'Elderly', 'Middle_Aged', 'Teenager','Young_Adults', 'Title', 'Master', 'Miss', 'Mr', 'Mrs', 'RareTitle','Fare_Cat','Fare_btw_10_25', 'Fare_lt10','Fare_mt100', 'Fare_mt25_50', 'Fare_mt50_100', \n",
    " 'Deck_A','Deck_B', 'Deck_C', 'Deck_D', 'Deck_E', 'Deck_F', 'Deck_G', 'U' ], axis=1, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.1 32-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0cfb223db4819573a1a735b7061e6260113ec44f4ccf8e030c31ccb798307531"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
